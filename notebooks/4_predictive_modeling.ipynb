{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd447b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TASK 4: PREDICTIVE MODELING FOR RISK-BASED PRICING\n",
      "================================================================================\n",
      "Data loaded: (1000096, 56)\n",
      "After dropping columns: (1000096, 17)\n",
      "After feature engineering: (1000096, 26)\n",
      "\n",
      "Severity model results:\n",
      "           Model         RMSE          MAE       R2\n",
      "    RandomForest 34561.937612 15760.674535 0.257249\n",
      "    DecisionTree 35350.376735 15911.170130 0.222975\n",
      "GradientBoosting 35576.869529 16364.494598 0.212986\n",
      "           Ridge 35799.455856 20251.869840 0.203107\n",
      "LinearRegression 35809.123039 20241.413776 0.202677\n",
      "         XGBoost 38044.833755 16864.632727 0.100009\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# TASK 4: PREDICTIVE MODELING\n",
    "# ============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modeling libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Regression & Classification models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# SHAP for interpretability\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TASK 4: PREDICTIVE MODELING FOR RISK-BASED PRICING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Data\n",
    "# -----------------------------\n",
    "df = pd.read_csv('../data/processed/processed_data.csv')\n",
    "df.columns = df.columns.str.strip()  # Strip extra spaces\n",
    "print(f\"Data loaded: {df.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Preparation\n",
    "# -----------------------------\n",
    "# Target variables\n",
    "df['ClaimOccurred'] = (df['TotalClaims'] > 0).astype(int)\n",
    "df['Margin'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = [\n",
    "    'UnderwrittenCoverID','PolicyID','TransactionMonth','VehicleIntroDate','YearMonth','LossRatio',\n",
    "    'NumberOfVehiclesInFleet','CrossBorder','Citizenship','LegalType','Title','Language','Bank',\n",
    "    'AccountType','MaritalStatus','Country','MainCrestaZone','SubCrestaZone','ItemType','mmcode',\n",
    "    'make','Model','CustomValueEstimate','AlarmImmobiliser','TrackingDevice','CapitalOutstanding',\n",
    "    'NewVehicle','WrittenOff','Rebuilt','Converted','TermFrequency','ExcessSelected','CoverCategory',\n",
    "    'CoverType','CoverGroup','Section','Product','StatutoryClass','StatutoryRiskType'\n",
    "]\n",
    "existing_drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "df_model = df.drop(columns=existing_drop_cols)\n",
    "print(f\"After dropping columns: {df_model.shape}\")\n",
    "\n",
    "# Missing value handling\n",
    "num_cols = df_model.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "num_cols = [c for c in num_cols if c not in ['TotalClaims','TotalPremium','ClaimOccurred','Margin']]\n",
    "for c in num_cols:\n",
    "    df_model[c].fillna(df_model[c].median(), inplace=True)\n",
    "\n",
    "cat_cols = df_model.select_dtypes(include=['object']).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    df_model[c].fillna(df_model[c].mode()[0] if not df_model[c].mode().empty else 'Unknown', inplace=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Feature Engineering\n",
    "# -----------------------------\n",
    "current_year = 2015\n",
    "df_model['VehicleAge'] = (current_year - df_model['RegistrationYear']).clip(0,50)\n",
    "df_model['PremiumToSumInsured'] = df_model['CalculatedPremiumPerTerm'] / (df_model['SumInsured']+1)\n",
    "\n",
    "# Convert Alarm/Tracking to binary\n",
    "df_model['HasAlarm'] = df.get('AlarmImmobiliser', pd.Series(0)).map({'Yes':1,'No':0}).fillna(0)\n",
    "df_model['HasTracking'] = df.get('TrackingDevice', pd.Series(0)).map({'Yes':1,'No':0}).fillna(0)\n",
    "\n",
    "# Log transform for monetary skew\n",
    "for col in ['TotalPremium','TotalClaims','SumInsured','CalculatedPremiumPerTerm','Margin']:\n",
    "    if col in df_model.columns:\n",
    "        df_model[f'Log_{col}'] = np.log1p(df_model[col].clip(lower=0))\n",
    "\n",
    "print(f\"After feature engineering: {df_model.shape}\")\n",
    "\n",
    "# ==============================\n",
    "# 4. Claim Severity Prediction\n",
    "# ==============================\n",
    "df_severity = df_model[df_model['TotalClaims']>0].copy()\n",
    "severity_features = [\n",
    "    'SumInsured','CalculatedPremiumPerTerm','VehicleAge','RegistrationYear',\n",
    "    'Cylinders','cubiccapacity','kilowatts','NumberOfDoors','VehicleType',\n",
    "    'bodytype','Province','Gender','PremiumToSumInsured','HasAlarm','HasTracking','PostalCode'\n",
    "]\n",
    "severity_features = [c for c in severity_features if c in df_severity.columns]\n",
    "X_sev = df_severity[severity_features]\n",
    "y_sev = df_severity['TotalClaims']\n",
    "\n",
    "# Split\n",
    "X_train_sev, X_test_sev, y_train_sev, y_test_sev = train_test_split(X_sev, y_sev, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "cat_feats_sev = X_sev.select_dtypes(include=['object']).columns.tolist()\n",
    "num_feats_sev = X_sev.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "preprocessor_sev = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='median'), num_feats_sev),\n",
    "    ('cat', Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "                      ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), cat_feats_sev)\n",
    "])\n",
    "\n",
    "# Models\n",
    "severity_models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'DecisionTree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100,max_depth=10,random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100,max_depth=5,random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100,max_depth=5,random_state=42,verbosity=0)\n",
    "}\n",
    "\n",
    "severity_results = []\n",
    "best_severity_model = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for name, model in severity_models.items():\n",
    "    pipe = Pipeline([('preprocessor', preprocessor_sev),\n",
    "                     ('scaler', StandardScaler()),\n",
    "                     ('model', model)])\n",
    "    pipe.fit(X_train_sev, y_train_sev)\n",
    "    y_pred = pipe.predict(X_test_sev)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_sev, y_pred))\n",
    "    mae = mean_absolute_error(y_test_sev, y_pred)\n",
    "    r2 = r2_score(y_test_sev, y_pred)\n",
    "    severity_results.append({'Model':name,'RMSE':rmse,'MAE':mae,'R2':r2})\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_severity_model = pipe\n",
    "\n",
    "severity_df = pd.DataFrame(severity_results).sort_values('RMSE')\n",
    "print(\"\\nSeverity model results:\")\n",
    "print(severity_df.to_string(index=False))\n",
    "\n",
    "# ==============================\n",
    "# 5. Claim Probability Prediction\n",
    "# ==============================\n",
    "# Avoid duplicate columns\n",
    "claim_prob_features = severity_features + ['VehicleAge','PremiumToSumInsured','HasAlarm','HasTracking']\n",
    "seen = set()\n",
    "claim_prob_features = [x for x in claim_prob_features if not (x in seen or seen.add(x))]\n",
    "\n",
    "X_prob = df_model[claim_prob_features]\n",
    "y_prob = df_model['ClaimOccurred']\n",
    "\n",
    "X_train_prob, X_test_prob, y_train_prob, y_test_prob = train_test_split(\n",
    "    X_prob, y_prob, test_size=0.2, random_state=42, stratify=y_prob)\n",
    "\n",
    "cat_feats_prob = X_prob.select_dtypes(include=['object']).columns.tolist()\n",
    "num_feats_prob = X_prob.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "preprocessor_prob = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='median'), num_feats_prob),\n",
    "    ('cat', Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "                      ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), cat_feats_prob)\n",
    "])\n",
    "\n",
    "classification_models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100,max_depth=10,random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100,max_depth=5,random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100,max_depth=5,random_state=42,verbosity=0)\n",
    "}\n",
    "\n",
    "classification_results = []\n",
    "best_classification_model = None\n",
    "best_f1 = 0\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    pipe = Pipeline([('preprocessor', preprocessor_prob),\n",
    "                     ('scaler', StandardScaler()),\n",
    "                     ('model', model)])\n",
    "    pipe.fit(X_train_prob, y_train_prob)\n",
    "    y_pred = pipe.predict(X_test_prob)\n",
    "    y_pred_proba = pipe.predict_proba(X_test_prob)[:,1]\n",
    "    accuracy = accuracy_score(y_test_prob, y_pred)\n",
    "    precision = precision_score(y_test_prob, y_pred)\n",
    "    recall = recall_score(y_test_prob, y_pred)\n",
    "    f1 = f1_score(y_test_prob, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_prob, y_pred_proba)\n",
    "    classification_results.append({'Model':name,'Accuracy':accuracy,'Precision':precision,\n",
    "                                   'Recall':recall,'F1-Score':f1,'ROC-AUC':roc_auc})\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_classification_model = pipe\n",
    "\n",
    "classification_df = pd.DataFrame(classification_results).sort_values('F1-Score', ascending=False)\n",
    "print(\"\\nClassification model results:\")\n",
    "print(classification_df.to_string(index=False))\n",
    "\n",
    "# ==============================\n",
    "# 6. Risk-Based Premium Calculation\n",
    "# ==============================\n",
    "print(\"\\nCalculating risk-based premiums for test set...\")\n",
    "prob_pred = best_classification_model.predict_proba(X_test_prob)[:,1]\n",
    "# Align arrays for risk-based premium (use test set from severity)\n",
    "sev_pred = best_severity_model.predict(X_test_sev[:len(prob_pred)])\n",
    "\n",
    "premium_pred = prob_pred * sev_pred\n",
    "df_risk_premium = pd.DataFrame({\n",
    "    'PredictedProbability': prob_pred,\n",
    "    'PredictedSeverity': sev_pred,\n",
    "    'RiskBasedPremium': premium_pred\n",
    "})\n",
    "print(df_risk_premium.head())\n",
    "\n",
    "# ==============================\n",
    "# 7. Model Interpretability (SHAP)\n",
    "# ==============================\n",
    "print(\"\\nRunning SHAP analysis for the best severity model...\")\n",
    "explainer = shap.Explainer(best_severity_model.named_steps['model'])\n",
    "X_sample = preprocessor_sev.transform(X_test_sev)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# Feature importance plot\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=preprocessor_sev.get_feature_names_out(), show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbae36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
