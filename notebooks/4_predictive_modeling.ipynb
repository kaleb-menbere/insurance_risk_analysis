{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd447b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modeling libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Interpretability\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TASK 4: PREDICTIVE MODELING FOR RISK-BASED PRICING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load the processed data\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/processed_data.csv')\n",
    "    print(f\"Data loaded successfully. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Processed data not found. Please run Task 1 first.\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Preparation for Modeling ---\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create target variables\n",
    "df['ClaimOccurred'] = (df['TotalClaims'] > 0).astype(int)\n",
    "df['Margin'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "# Feature Selection\n",
    "# Remove columns with too many missing values or irrelevant for prediction\n",
    "drop_cols = [\n",
    "    'UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', \n",
    "    'VehicleIntroDate', 'YearMonth', 'LossRatio',\n",
    "    'NumberOfVehiclesInFleet', 'CrossBorder',  # Too many missing\n",
    "    'Citizenship', 'LegalType', 'Title', 'Language', 'Bank',  # Too many categories/missing\n",
    "    'AccountType', 'MaritalStatus', 'Country', 'MainCrestaZone',\n",
    "    'SubCrestaZone', 'ItemType', 'mmcode', 'make', 'Model',\n",
    "    'CustomValueEstimate', 'AlarmImmobiliser', 'TrackingDevice',\n",
    "    'CapitalOutstanding', 'NewVehicle', 'WrittenOff', 'Rebuilt',\n",
    "    'Converted', 'TermFrequency', 'ExcessSelected', 'CoverCategory',\n",
    "    'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass',\n",
    "    'StatutoryRiskType'\n",
    "]\n",
    "\n",
    "# Keep only columns that exist\n",
    "existing_drop_cols = [col for col in drop_cols if col in df.columns]\n",
    "df_model = df.drop(columns=existing_drop_cols)\n",
    "\n",
    "print(f\"After dropping irrelevant columns: {df_model.shape}\")\n",
    "\n",
    "# Handle missing values\n",
    "missing_before = df_model.isnull().sum().sum()\n",
    "print(f\"Missing values before cleaning: {missing_before}\")\n",
    "\n",
    "# Impute numerical columns with median\n",
    "numerical_cols = df_model.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['TotalClaims', 'TotalPremium', 'ClaimOccurred', 'Margin']]\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if df_model[col].isnull().sum() > 0:\n",
    "        df_model[col] = df_model[col].fillna(df_model[col].median())\n",
    "\n",
    "# Impute categorical columns with mode\n",
    "categorical_cols = df_model.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    if df_model[col].isnull().sum() > 0:\n",
    "        df_model[col] = df_model[col].fillna(df_model[col].mode()[0] if not df_model[col].mode().empty else 'Unknown')\n",
    "\n",
    "missing_after = df_model.isnull().sum().sum()\n",
    "print(f\"Missing values after cleaning: {missing_after}\")\n",
    "\n",
    "# Feature Engineering\n",
    "print(\"\\n--- Feature Engineering ---\")\n",
    "\n",
    "# 1. Vehicle Age\n",
    "current_year = 2015  # Based on data timeframe\n",
    "df_model['VehicleAge'] = current_year - df_model['RegistrationYear']\n",
    "df_model['VehicleAge'] = df_model['VehicleAge'].clip(lower=0, upper=50)  # Cap at 50 years\n",
    "\n",
    "# 2. Premium to SumInsured Ratio\n",
    "df_model['PremiumToSumInsured'] = df_model['CalculatedPremiumPerTerm'] / (df_model['SumInsured'] + 1)\n",
    "\n",
    "# 3. Binary features from categorical\n",
    "df_model['HasAlarm'] = df_model['AlarmImmobiliser'].notnull().astype(int)\n",
    "df_model['HasTracking'] = df_model['TrackingDevice'].notnull().astype(int)\n",
    "\n",
    "# 4. Log transform for skewed monetary variables\n",
    "for col in ['TotalPremium', 'TotalClaims', 'SumInsured', 'CalculatedPremiumPerTerm', 'Margin']:\n",
    "    if col in df_model.columns:\n",
    "        df_model[f'Log_{col}'] = np.log1p(df_model[col].clip(lower=0))\n",
    "\n",
    "print(f\"After feature engineering: {df_model.shape}\")\n",
    "\n",
    "# --- MODEL 1: Claim Severity Prediction ---\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL 1: CLAIM SEVERITY PREDICTION\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Target: TotalClaims (only for policies with claims > 0)\")\n",
    "print(\"Goal: Predict claim amount given a claim occurred\")\n",
    "\n",
    "# Filter for claims only\n",
    "df_severity = df_model[df_model['TotalClaims'] > 0].copy()\n",
    "print(f\"Severity dataset: {len(df_severity)} claims\")\n",
    "\n",
    "# Define features and target for severity\n",
    "severity_features = [\n",
    "    'SumInsured', 'CalculatedPremiumPerTerm', 'VehicleAge',\n",
    "    'RegistrationYear', 'Cylinders', 'cubiccapacity', 'kilowatts',\n",
    "    'NumberOfDoors', 'VehicleType', 'bodytype', 'Province', 'Gender',\n",
    "    'PremiumToSumInsured', 'HasAlarm', 'HasTracking', 'PostalCode'\n",
    "]\n",
    "\n",
    "# Keep only existing features\n",
    "severity_features = [col for col in severity_features if col in df_severity.columns]\n",
    "\n",
    "X_sev = df_severity[severity_features]\n",
    "y_sev = df_severity['TotalClaims']\n",
    "\n",
    "print(f\"Severity features: {len(severity_features)}\")\n",
    "print(f\"Target range: R{y_sev.min():,.0f} to R{y_sev.max():,.0f}\")\n",
    "print(f\"Mean claim amount: R{y_sev.mean():,.0f}\")\n",
    "\n",
    "# Split data\n",
    "X_train_sev, X_test_sev, y_train_sev, y_test_sev = train_test_split(\n",
    "    X_sev, y_sev, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train_sev):,}\")\n",
    "print(f\"Test size: {len(X_test_sev):,}\")\n",
    "\n",
    "# Define preprocessing\n",
    "categorical_features_sev = X_sev.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features_sev = X_sev.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "preprocessor_sev = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numerical_features_sev),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_features_sev)\n",
    "    ])\n",
    "\n",
    "# Define models\n",
    "severity_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, max_depth=5, random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "severity_results = []\n",
    "best_severity_model = None\n",
    "best_severity_score = float('inf')\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Training Severity Models...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, model in severity_models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor_sev),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train\n",
    "    pipeline.fit(X_train_sev, y_train_sev)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = pipeline.predict(X_test_sev)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_sev, y_pred))\n",
    "    mae = mean_absolute_error(y_test_sev, y_pred)\n",
    "    r2 = r2_score(y_test_sev, y_pred)\n",
    "    \n",
    "    print(f\"  RMSE: R{rmse:,.2f}\")\n",
    "    print(f\"  MAE: R{mae:,.2f}\")\n",
    "    print(f\"  R²: {r2:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    result = {\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2\n",
    "    }\n",
    "    severity_results.append(result)\n",
    "    \n",
    "    # Track best model\n",
    "    if rmse < best_severity_score:\n",
    "        best_severity_score = rmse\n",
    "        best_severity_model = pipeline\n",
    "\n",
    "# Display severity results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEVERITY MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "severity_df = pd.DataFrame(severity_results).sort_values('RMSE')\n",
    "print(severity_df.to_string(index=False))\n",
    "\n",
    "# --- MODEL 2: Claim Probability Prediction ---\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL 2: CLAIM PROBABILITY PREDICTION\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Target: ClaimOccurred (binary: 0 = no claim, 1 = claim)\")\n",
    "print(\"Goal: Predict probability of a claim occurring\")\n",
    "\n",
    "# Use entire dataset for claim probability\n",
    "df_claim_prob = df_model.copy()\n",
    "\n",
    "# Define features for claim probability (can include more features)\n",
    "claim_prob_features = severity_features + ['VehicleAge', 'PremiumToSumInsured', 'HasAlarm', 'HasTracking']\n",
    "\n",
    "# Keep only existing features\n",
    "claim_prob_features = [col for col in claim_prob_features if col in df_claim_prob.columns]\n",
    "\n",
    "X_prob = df_claim_prob[claim_prob_features]\n",
    "y_prob = df_claim_prob['ClaimOccurred']\n",
    "\n",
    "print(f\"Claim probability dataset: {len(X_prob):,} policies\")\n",
    "print(f\"Claim rate: {y_prob.mean():.4f} ({y_prob.sum():,} claims)\")\n",
    "print(f\"Features: {len(claim_prob_features)}\")\n",
    "\n",
    "# Split data\n",
    "X_train_prob, X_test_prob, y_train_prob, y_test_prob = train_test_split(\n",
    "    X_prob, y_prob, test_size=0.2, random_state=42, stratify=y_prob\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train_prob):,}\")\n",
    "print(f\"Test size: {len(X_test_prob):,}\")\n",
    "\n",
    "# Define preprocessing for probability model\n",
    "categorical_features_prob = X_prob.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features_prob = X_prob.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "preprocessor_prob = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numerical_features_prob),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_features_prob)\n",
    "    ])\n",
    "\n",
    "# Define classification models\n",
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'XGBoost Classifier': XGBClassifier(n_estimators=100, max_depth=5, random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "# Train and evaluate classification models\n",
    "classification_results = []\n",
    "best_classification_model = None\n",
    "best_classification_score = 0\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Training Classification Models...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor_prob),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train\n",
    "    pipeline.fit(X_train_prob, y_train_prob)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = pipeline.predict(X_test_prob)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test_prob)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_prob, y_pred)\n",
    "    precision = precision_score(y_test_prob, y_pred)\n",
    "    recall = recall_score(y_test_prob, y_pred)\n",
    "    f1 = f1_score(y_test_prob, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_prob, y_pred_proba)\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    result = {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "    classification_results.append(result)\n",
    "    \n",
    "    # Track best model (by F1-score)\n",
    "    if f1 > best_classification_score:\n",
    "        best_classification_score = f1\n",
    "        best_classification_model = pipeline\n",
    "\n",
    "# Display classification results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASSIFICATION MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "classification_df = pd.DataFrame(classification_results).sort_values('F1-Score', ascending=False)\n",
    "print(classification_df.to_string(index=False))\n",
    "\n",
    "# --- MODEL 3: Risk-Based Premium Calculation ---\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL 3: RISK-BASED PREMIUM CALCULATION\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Concept: Premium = (Predicted Probability × Predicted Severity) + Costs + Profit Margin\")\n",
    "\n",
    "# Use best models to calculate risk-based premium\n",
    "print(\"\\nCalculating risk-based premiums for test set...\")\n",
    "\n",
    "# Get claim probabilities\n",
    "y_prob_pred = best_classification_model.predict_proba(X_test_prob)[:, 1]\n",
    "\n",
    "# Get severity predictions (need to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
